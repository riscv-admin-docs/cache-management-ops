# Minutes (2022-02-28)

- Defined the "large buffer" problem
  - Simple problem statement: How to manage buffers that are much larger than the caches?
  - Agreed to adopt current CBO semantics and use-cases for non-coherent I/O or other agents

- Philosophical viewpoints:
  - Need an Architecture solution, i.e. a definition that spans multiple implementations and does not constrain possible microarchitectures
  - Implementation of solution can use trap and emulate as an escape valve

- Baseline implementation of large buffer operation: SW loop over buffer with existing CBO instructions; what can be done better?
  - Performance limiter is due to global operations across the entire cache hierarchy
  - "Standard" bus protocols not really designed to handle larger units than a cache block; anything larger requires custom implementation
  - Contiguous buffer in VA space or Guest PA space is not necessarily contiguous in PA space, so there is a practical upper bound that can be transmitted based on translation

- What about portability (instead of performance)?
  - There is a desire for portability, but how?
  - Portable via ISA or software calls, i.e. SBI?

- Common system: single cluster of CPUs with an inclusive shared L2 as the LLC
  - In such a system, a large buffer operation can be implemented as a series of set/way operations on the L2
  - What happens in systems with multiple clusters?
    - Iterating over sets and ways is not atomic with respect to other clusters, e.g. lateral castouts can bounce lines among clusters without moving data to the point where it is visible to a non-coherent agent
  - Possible abstraction (for both ISA and SBI) is to define subsets of caches operated on, e.g. a "cluster cache all" operation
    - Definition of semantics becomes an issue; constraints placed on implementations (e.g. lateral castouts disallowed)
    - Architecturally abstract, but system-specific definition (may or may not have desired effect on all systems, but that may be sufficient for some)

- For some systems, concurrency of a HW state machine operating on large buffers is important (SW loop is a performance limiter)

- Trap and emulate vs. SBI call: likely to have the same performance characteristics in SW

- Next step(s):
  - Explore feasibility of SW call, e.g. SBI, to hide cache management details
